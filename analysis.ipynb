{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Official\n",
    "import pandas\n",
    "import copy\n",
    "import numpy\n",
    "import torch\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Custom\n",
    "from utils import modify_space_data\n",
    "from torch_model import SpaceData, CustomModel, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data_path: \"str\" = \"~/Desktop/spaceship_titanic/data/train.csv\"\n",
    "train_data: \"DataFrame\" = pandas.read_csv(train_data_path)\n",
    "\n",
    "# Load test data\n",
    "test_data_path: \"str\" = \"~/Desktop/spaceship_titanic/data/test.csv\"\n",
    "test_data: \"DataFrame\" = pandas.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- PassengerId: Must be split into group number and group member\n",
    "- HomePlanet: Is class variable with 3 classes\n",
    "- CryoSleep: Is boolean variable\n",
    "- Cabin: Must be split into three class variables\n",
    "- Age: A numeric variable\n",
    "- VIP: A boolean variable\n",
    "- RoomService: Numeric, predominantly 0\n",
    "- FoodCourt: Numeric, predominantly 0\n",
    "- ShoppingMall: Numeric, predominantly 0\n",
    "- Spa: Numeric, predominantly 0\n",
    "- VRDeck: Numeric, predominantly 0\n",
    "- Name: Purely ID based (Can be used for identifying families)\n",
    "- Transported: Boolean variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True     4378\n",
       "False    4315\n",
       "Name: Transported, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code for analysing features\n",
    "\n",
    "# For showing number of unique entries\n",
    "train_data.nunique()\n",
    "\n",
    "# For showing histograms of different columns\n",
    "plt.hist(train_data[\"VRDeck\"])\n",
    "plt.show()\n",
    "\n",
    "# For showing the counts of unique values in a column\n",
    "train_data[\"Transported\"].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject: \"str\" = \"Transported\"\n",
    "\n",
    "edit_data: \"DataFrame\" = modify_space_data(train_data)\n",
    "\n",
    "labels: \"DataFrame\" = copy.deepcopy(edit_data[subject])\n",
    "features: \"DataFrame\" = copy.deepcopy(edit_data.drop([subject], axis=1))\n",
    "\n",
    "validation_size: \"float\" = 0.2\n",
    "random_state: \"int\" = 2\n",
    "\n",
    "train_features, val_features, train_labels, val_labels = train_test_split(features,labels,test_size=validation_size,random_state=random_state)\n",
    "test_features: \"DataFrame\" = modify_space_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80448533640023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model: \"LogisticRegression\" = LogisticRegression(penalty=\"l2\", max_iter=10000, random_state=random_state)\n",
    "fitted_model = logistic_model.fit(train_features, train_labels)\n",
    "logistic_accuracy: \"float\" = fitted_model.score(val_features, val_labels)\n",
    "\n",
    "print(logistic_accuracy)\n",
    "\n",
    "fitted_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_train_dataset = SpaceData(X=train_features,y=train_labels)\n",
    "space_val_dataset = SpaceData(X=val_features,y=val_labels)\n",
    "space_test_dataset = SpaceData(X=test_features,y=test_features[\"Age\"])\n",
    "\n",
    "space_train_dataloader = DataLoader(dataset=space_train_dataset, batch_size=len(space_train_dataset), shuffle=True)\n",
    "space_val_dataloader = DataLoader(dataset=space_val_dataset, batch_size=len(space_val_dataset), shuffle=True)\n",
    "space_test_dataloader = DataLoader(dataset=space_test_dataset, batch_size=len(space_test_dataset), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now's the time to get out the big guns (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = CustomModel()\n",
    "\n",
    "loss_model = torch.nn.BCELoss()\n",
    "\n",
    "optimiser = torch.optim.SGD(custom_model.parameters(), lr=10 ** (-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.604505, accuracy: 0.787234  [    1/ 1000]\n",
      "loss: 0.605067, accuracy: 0.787809  [    2/ 1000]\n",
      "loss: 0.604310, accuracy: 0.786659  [    3/ 1000]\n",
      "loss: 0.603733, accuracy: 0.786659  [    4/ 1000]\n",
      "loss: 0.603186, accuracy: 0.787234  [    5/ 1000]\n",
      "loss: 0.602774, accuracy: 0.787809  [    6/ 1000]\n",
      "loss: 0.602329, accuracy: 0.787234  [    7/ 1000]\n",
      "loss: 0.602018, accuracy: 0.787234  [    8/ 1000]\n",
      "loss: 0.601612, accuracy: 0.787234  [    9/ 1000]\n",
      "loss: 0.601386, accuracy: 0.787234  [   10/ 1000]\n",
      "loss: 0.600967, accuracy: 0.787234  [   11/ 1000]\n",
      "loss: 0.600837, accuracy: 0.787234  [   12/ 1000]\n",
      "loss: 0.600341, accuracy: 0.787234  [   13/ 1000]\n",
      "loss: 0.600374, accuracy: 0.787234  [   14/ 1000]\n",
      "loss: 0.599688, accuracy: 0.787234  [   15/ 1000]\n",
      "loss: 0.600037, accuracy: 0.788384  [   16/ 1000]\n",
      "loss: 0.598934, accuracy: 0.787234  [   17/ 1000]\n",
      "loss: 0.599943, accuracy: 0.787809  [   18/ 1000]\n",
      "loss: 0.597942, accuracy: 0.786659  [   19/ 1000]\n",
      "loss: 0.600410, accuracy: 0.787809  [   20/ 1000]\n",
      "loss: 0.596505, accuracy: 0.786659  [   21/ 1000]\n",
      "loss: 0.602353, accuracy: 0.788384  [   22/ 1000]\n",
      "loss: 0.594640, accuracy: 0.786084  [   23/ 1000]\n",
      "loss: 0.608751, accuracy: 0.785509  [   24/ 1000]\n",
      "loss: 0.596104, accuracy: 0.779183  [   25/ 1000]\n",
      "loss: 0.624641, accuracy: 0.777458  [   26/ 1000]\n",
      "loss: 0.618625, accuracy: 0.770558  [   27/ 1000]\n",
      "loss: 0.679799, accuracy: 0.764232  [   28/ 1000]\n",
      "loss: 0.854251, accuracy: 0.752731  [   29/ 1000]\n",
      "loss: 0.709525, accuracy: 0.759632  [   30/ 1000]\n",
      "loss: 0.776872, accuracy: 0.768258  [   31/ 1000]\n",
      "loss: 0.644380, accuracy: 0.782059  [   32/ 1000]\n",
      "loss: 0.606283, accuracy: 0.782634  [   33/ 1000]\n",
      "loss: 0.609673, accuracy: 0.786084  [   34/ 1000]\n",
      "loss: 0.602283, accuracy: 0.784934  [   35/ 1000]\n",
      "loss: 0.603217, accuracy: 0.787234  [   36/ 1000]\n",
      "loss: 0.599556, accuracy: 0.786084  [   37/ 1000]\n",
      "loss: 0.600128, accuracy: 0.786659  [   38/ 1000]\n",
      "loss: 0.597624, accuracy: 0.787234  [   39/ 1000]\n",
      "loss: 0.598433, accuracy: 0.787234  [   40/ 1000]\n",
      "loss: 0.596186, accuracy: 0.787234  [   41/ 1000]\n",
      "loss: 0.597552, accuracy: 0.786659  [   42/ 1000]\n",
      "loss: 0.594932, accuracy: 0.786659  [   43/ 1000]\n",
      "loss: 0.597376, accuracy: 0.787234  [   44/ 1000]\n",
      "loss: 0.593581, accuracy: 0.786659  [   45/ 1000]\n",
      "loss: 0.598260, accuracy: 0.787234  [   46/ 1000]\n",
      "loss: 0.591944, accuracy: 0.786659  [   47/ 1000]\n",
      "loss: 0.601594, accuracy: 0.787809  [   48/ 1000]\n",
      "loss: 0.590833, accuracy: 0.784359  [   49/ 1000]\n",
      "loss: 0.611755, accuracy: 0.786084  [   50/ 1000]\n",
      "loss: 0.599923, accuracy: 0.777458  [   51/ 1000]\n",
      "loss: 0.643686, accuracy: 0.776883  [   52/ 1000]\n",
      "loss: 0.655382, accuracy: 0.765382  [   53/ 1000]\n",
      "loss: 0.707600, accuracy: 0.754457  [   54/ 1000]\n",
      "loss: 0.915923, accuracy: 0.752731  [   55/ 1000]\n",
      "loss: 0.673519, accuracy: 0.775733  [   56/ 1000]\n",
      "loss: 0.625158, accuracy: 0.778033  [   57/ 1000]\n",
      "loss: 0.620255, accuracy: 0.785509  [   58/ 1000]\n",
      "loss: 0.599729, accuracy: 0.782634  [   59/ 1000]\n",
      "loss: 0.602413, accuracy: 0.786659  [   60/ 1000]\n",
      "loss: 0.597623, accuracy: 0.784934  [   61/ 1000]\n",
      "loss: 0.598066, accuracy: 0.785509  [   62/ 1000]\n",
      "loss: 0.595241, accuracy: 0.787234  [   63/ 1000]\n",
      "loss: 0.595727, accuracy: 0.787234  [   64/ 1000]\n",
      "loss: 0.593560, accuracy: 0.786659  [   65/ 1000]\n",
      "loss: 0.594419, accuracy: 0.788384  [   66/ 1000]\n",
      "loss: 0.592250, accuracy: 0.786659  [   67/ 1000]\n",
      "loss: 0.593810, accuracy: 0.787234  [   68/ 1000]\n",
      "loss: 0.591016, accuracy: 0.787234  [   69/ 1000]\n",
      "loss: 0.593968, accuracy: 0.787809  [   70/ 1000]\n",
      "loss: 0.589588, accuracy: 0.787234  [   71/ 1000]\n",
      "loss: 0.595572, accuracy: 0.786659  [   72/ 1000]\n",
      "loss: 0.587934, accuracy: 0.785509  [   73/ 1000]\n",
      "loss: 0.601076, accuracy: 0.787809  [   74/ 1000]\n",
      "loss: 0.589039, accuracy: 0.782634  [   75/ 1000]\n",
      "loss: 0.619994, accuracy: 0.780334  [   76/ 1000]\n",
      "loss: 0.618437, accuracy: 0.766532  [   77/ 1000]\n",
      "loss: 0.683604, accuracy: 0.763082  [   78/ 1000]\n",
      "loss: 0.856179, accuracy: 0.752156  [   79/ 1000]\n",
      "loss: 0.703847, accuracy: 0.763657  [   80/ 1000]\n",
      "loss: 0.762796, accuracy: 0.769408  [   81/ 1000]\n",
      "loss: 0.636897, accuracy: 0.783209  [   82/ 1000]\n",
      "loss: 0.600029, accuracy: 0.783784  [   83/ 1000]\n",
      "loss: 0.604544, accuracy: 0.785509  [   84/ 1000]\n",
      "loss: 0.595231, accuracy: 0.783209  [   85/ 1000]\n",
      "loss: 0.597265, accuracy: 0.786084  [   86/ 1000]\n",
      "loss: 0.592705, accuracy: 0.784934  [   87/ 1000]\n",
      "loss: 0.594013, accuracy: 0.786084  [   88/ 1000]\n",
      "loss: 0.590817, accuracy: 0.784934  [   89/ 1000]\n",
      "loss: 0.592305, accuracy: 0.786084  [   90/ 1000]\n",
      "loss: 0.589336, accuracy: 0.784934  [   91/ 1000]\n",
      "loss: 0.591560, accuracy: 0.787234  [   92/ 1000]\n",
      "loss: 0.587969, accuracy: 0.785509  [   93/ 1000]\n",
      "loss: 0.591830, accuracy: 0.787809  [   94/ 1000]\n",
      "loss: 0.586451, accuracy: 0.785509  [   95/ 1000]\n",
      "loss: 0.594023, accuracy: 0.786659  [   96/ 1000]\n",
      "loss: 0.585019, accuracy: 0.785509  [   97/ 1000]\n",
      "loss: 0.601767, accuracy: 0.787234  [   98/ 1000]\n",
      "loss: 0.590287, accuracy: 0.779758  [   99/ 1000]\n",
      "loss: 0.632312, accuracy: 0.777458  [  100/ 1000]\n",
      "loss: 0.641158, accuracy: 0.767108  [  101/ 1000]\n",
      "loss: 0.707931, accuracy: 0.755607  [  102/ 1000]\n",
      "loss: 0.883286, accuracy: 0.744681  [  103/ 1000]\n",
      "loss: 0.693785, accuracy: 0.767683  [  104/ 1000]\n",
      "loss: 0.637098, accuracy: 0.773433  [  105/ 1000]\n",
      "loss: 0.623749, accuracy: 0.786084  [  106/ 1000]\n",
      "loss: 0.596576, accuracy: 0.782059  [  107/ 1000]\n",
      "loss: 0.600584, accuracy: 0.786084  [  108/ 1000]\n",
      "loss: 0.593166, accuracy: 0.783209  [  109/ 1000]\n",
      "loss: 0.594291, accuracy: 0.787234  [  110/ 1000]\n",
      "loss: 0.590506, accuracy: 0.785509  [  111/ 1000]\n",
      "loss: 0.591184, accuracy: 0.786659  [  112/ 1000]\n",
      "loss: 0.588541, accuracy: 0.785509  [  113/ 1000]\n",
      "loss: 0.589429, accuracy: 0.785509  [  114/ 1000]\n",
      "loss: 0.587044, accuracy: 0.784934  [  115/ 1000]\n",
      "loss: 0.588528, accuracy: 0.785509  [  116/ 1000]\n",
      "loss: 0.585736, accuracy: 0.785509  [  117/ 1000]\n",
      "loss: 0.588457, accuracy: 0.787234  [  118/ 1000]\n",
      "loss: 0.584322, accuracy: 0.785509  [  119/ 1000]\n",
      "loss: 0.589834, accuracy: 0.787809  [  120/ 1000]\n",
      "loss: 0.582708, accuracy: 0.784934  [  121/ 1000]\n",
      "loss: 0.595394, accuracy: 0.787809  [  122/ 1000]\n",
      "loss: 0.584392, accuracy: 0.780334  [  123/ 1000]\n",
      "loss: 0.618059, accuracy: 0.781484  [  124/ 1000]\n",
      "loss: 0.622317, accuracy: 0.767108  [  125/ 1000]\n",
      "loss: 0.691663, accuracy: 0.759632  [  126/ 1000]\n",
      "loss: 0.866314, accuracy: 0.746981  [  127/ 1000]\n",
      "loss: 0.700248, accuracy: 0.763657  [  128/ 1000]\n",
      "loss: 0.651868, accuracy: 0.771133  [  129/ 1000]\n",
      "loss: 0.627824, accuracy: 0.785509  [  130/ 1000]\n",
      "loss: 0.594559, accuracy: 0.783209  [  131/ 1000]\n",
      "loss: 0.600245, accuracy: 0.785509  [  132/ 1000]\n",
      "loss: 0.590180, accuracy: 0.782634  [  133/ 1000]\n",
      "loss: 0.592617, accuracy: 0.787809  [  134/ 1000]\n",
      "loss: 0.587657, accuracy: 0.783209  [  135/ 1000]\n",
      "loss: 0.589243, accuracy: 0.786084  [  136/ 1000]\n",
      "loss: 0.585721, accuracy: 0.784934  [  137/ 1000]\n",
      "loss: 0.587488, accuracy: 0.784359  [  138/ 1000]\n",
      "loss: 0.584171, accuracy: 0.785509  [  139/ 1000]\n",
      "loss: 0.586807, accuracy: 0.786084  [  140/ 1000]\n",
      "loss: 0.582717, accuracy: 0.784359  [  141/ 1000]\n",
      "loss: 0.587417, accuracy: 0.786659  [  142/ 1000]\n",
      "loss: 0.581133, accuracy: 0.784359  [  143/ 1000]\n",
      "loss: 0.591032, accuracy: 0.787234  [  144/ 1000]\n",
      "loss: 0.580798, accuracy: 0.782059  [  145/ 1000]\n",
      "loss: 0.606021, accuracy: 0.786659  [  146/ 1000]\n",
      "loss: 0.603435, accuracy: 0.770558  [  147/ 1000]\n",
      "loss: 0.671903, accuracy: 0.767108  [  148/ 1000]\n",
      "loss: 0.838354, accuracy: 0.755607  [  149/ 1000]\n",
      "loss: 0.716877, accuracy: 0.757907  [  150/ 1000]\n",
      "loss: 0.828608, accuracy: 0.769983  [  151/ 1000]\n",
      "loss: 0.644499, accuracy: 0.782059  [  152/ 1000]\n",
      "loss: 0.603390, accuracy: 0.783209  [  153/ 1000]\n",
      "loss: 0.603761, accuracy: 0.784934  [  154/ 1000]\n",
      "loss: 0.589993, accuracy: 0.783209  [  155/ 1000]\n",
      "loss: 0.592486, accuracy: 0.787234  [  156/ 1000]\n",
      "loss: 0.587057, accuracy: 0.783784  [  157/ 1000]\n",
      "loss: 0.588127, accuracy: 0.787234  [  158/ 1000]\n",
      "loss: 0.584815, accuracy: 0.784359  [  159/ 1000]\n",
      "loss: 0.585793, accuracy: 0.785509  [  160/ 1000]\n",
      "loss: 0.583121, accuracy: 0.786084  [  161/ 1000]\n",
      "loss: 0.584536, accuracy: 0.784934  [  162/ 1000]\n",
      "loss: 0.581718, accuracy: 0.786084  [  163/ 1000]\n",
      "loss: 0.584177, accuracy: 0.786084  [  164/ 1000]\n",
      "loss: 0.580305, accuracy: 0.785509  [  165/ 1000]\n",
      "loss: 0.585226, accuracy: 0.786659  [  166/ 1000]\n",
      "loss: 0.578692, accuracy: 0.783784  [  167/ 1000]\n",
      "loss: 0.590474, accuracy: 0.788384  [  168/ 1000]\n",
      "loss: 0.580438, accuracy: 0.779758  [  169/ 1000]\n",
      "loss: 0.614913, accuracy: 0.782059  [  170/ 1000]\n",
      "loss: 0.619922, accuracy: 0.770558  [  171/ 1000]\n",
      "loss: 0.690172, accuracy: 0.759632  [  172/ 1000]\n",
      "loss: 0.858905, accuracy: 0.748131  [  173/ 1000]\n",
      "loss: 0.695378, accuracy: 0.765382  [  174/ 1000]\n",
      "loss: 0.644580, accuracy: 0.775158  [  175/ 1000]\n",
      "loss: 0.624428, accuracy: 0.786659  [  176/ 1000]\n",
      "loss: 0.591150, accuracy: 0.784359  [  177/ 1000]\n",
      "loss: 0.597714, accuracy: 0.786084  [  178/ 1000]\n",
      "loss: 0.585830, accuracy: 0.782634  [  179/ 1000]\n",
      "loss: 0.589200, accuracy: 0.787234  [  180/ 1000]\n",
      "loss: 0.583384, accuracy: 0.783209  [  181/ 1000]\n",
      "loss: 0.585625, accuracy: 0.784934  [  182/ 1000]\n",
      "loss: 0.581457, accuracy: 0.783784  [  183/ 1000]\n",
      "loss: 0.583871, accuracy: 0.785509  [  184/ 1000]\n",
      "loss: 0.579851, accuracy: 0.784934  [  185/ 1000]\n",
      "loss: 0.583399, accuracy: 0.786659  [  186/ 1000]\n",
      "loss: 0.578291, accuracy: 0.784934  [  187/ 1000]\n",
      "loss: 0.584848, accuracy: 0.787234  [  188/ 1000]\n",
      "loss: 0.576838, accuracy: 0.783784  [  189/ 1000]\n",
      "loss: 0.592335, accuracy: 0.787809  [  190/ 1000]\n",
      "loss: 0.583697, accuracy: 0.780909  [  191/ 1000]\n",
      "loss: 0.630725, accuracy: 0.778608  [  192/ 1000]\n",
      "loss: 0.637380, accuracy: 0.769408  [  193/ 1000]\n",
      "loss: 0.701123, accuracy: 0.761357  [  194/ 1000]\n",
      "loss: 0.854601, accuracy: 0.752156  [  195/ 1000]\n",
      "loss: 0.679517, accuracy: 0.772858  [  196/ 1000]\n",
      "loss: 0.625187, accuracy: 0.776883  [  197/ 1000]\n",
      "loss: 0.619943, accuracy: 0.785509  [  198/ 1000]\n",
      "loss: 0.588582, accuracy: 0.783784  [  199/ 1000]\n",
      "loss: 0.595775, accuracy: 0.785509  [  200/ 1000]\n",
      "loss: 0.583848, accuracy: 0.783209  [  201/ 1000]\n",
      "loss: 0.587471, accuracy: 0.786659  [  202/ 1000]\n",
      "loss: 0.581530, accuracy: 0.783784  [  203/ 1000]\n",
      "loss: 0.583961, accuracy: 0.786084  [  204/ 1000]\n",
      "loss: 0.579654, accuracy: 0.783209  [  205/ 1000]\n",
      "loss: 0.582273, accuracy: 0.786659  [  206/ 1000]\n",
      "loss: 0.578045, accuracy: 0.783784  [  207/ 1000]\n",
      "loss: 0.581943, accuracy: 0.786659  [  208/ 1000]\n",
      "loss: 0.576450, accuracy: 0.785509  [  209/ 1000]\n",
      "loss: 0.583903, accuracy: 0.787234  [  210/ 1000]\n",
      "loss: 0.575260, accuracy: 0.783209  [  211/ 1000]\n",
      "loss: 0.594037, accuracy: 0.786659  [  212/ 1000]\n",
      "loss: 0.587871, accuracy: 0.780909  [  213/ 1000]\n",
      "loss: 0.648406, accuracy: 0.773433  [  214/ 1000]\n",
      "loss: 0.756385, accuracy: 0.764232  [  215/ 1000]\n",
      "loss: 0.704931, accuracy: 0.764232  [  216/ 1000]\n",
      "loss: 0.832578, accuracy: 0.765382  [  217/ 1000]\n",
      "loss: 0.664022, accuracy: 0.778608  [  218/ 1000]\n",
      "loss: 0.615371, accuracy: 0.778608  [  219/ 1000]\n",
      "loss: 0.614035, accuracy: 0.784934  [  220/ 1000]\n",
      "loss: 0.585673, accuracy: 0.785509  [  221/ 1000]\n",
      "loss: 0.593060, accuracy: 0.784934  [  222/ 1000]\n",
      "loss: 0.581799, accuracy: 0.784934  [  223/ 1000]\n",
      "loss: 0.585538, accuracy: 0.786084  [  224/ 1000]\n",
      "loss: 0.579595, accuracy: 0.785509  [  225/ 1000]\n",
      "loss: 0.582284, accuracy: 0.788384  [  226/ 1000]\n",
      "loss: 0.577765, accuracy: 0.784359  [  227/ 1000]\n",
      "loss: 0.580808, accuracy: 0.788384  [  228/ 1000]\n",
      "loss: 0.576133, accuracy: 0.785509  [  229/ 1000]\n",
      "loss: 0.580874, accuracy: 0.788959  [  230/ 1000]\n",
      "loss: 0.574504, accuracy: 0.784359  [  231/ 1000]\n",
      "loss: 0.584192, accuracy: 0.790109  [  232/ 1000]\n",
      "loss: 0.574623, accuracy: 0.783209  [  233/ 1000]\n",
      "loss: 0.601170, accuracy: 0.783784  [  234/ 1000]\n",
      "loss: 0.599907, accuracy: 0.774008  [  235/ 1000]\n",
      "loss: 0.679275, accuracy: 0.765382  [  236/ 1000]\n",
      "loss: 0.843900, accuracy: 0.749281  [  237/ 1000]\n",
      "loss: 0.719780, accuracy: 0.755607  [  238/ 1000]\n",
      "loss: 0.816096, accuracy: 0.772858  [  239/ 1000]\n",
      "loss: 0.633038, accuracy: 0.785509  [  240/ 1000]\n",
      "loss: 0.594253, accuracy: 0.786659  [  241/ 1000]\n",
      "loss: 0.596931, accuracy: 0.786084  [  242/ 1000]\n",
      "loss: 0.583508, accuracy: 0.784934  [  243/ 1000]\n",
      "loss: 0.586055, accuracy: 0.787234  [  244/ 1000]\n",
      "loss: 0.580528, accuracy: 0.784359  [  245/ 1000]\n",
      "loss: 0.581654, accuracy: 0.786659  [  246/ 1000]\n",
      "loss: 0.578205, accuracy: 0.785509  [  247/ 1000]\n",
      "loss: 0.579291, accuracy: 0.787809  [  248/ 1000]\n",
      "loss: 0.576391, accuracy: 0.786084  [  249/ 1000]\n",
      "loss: 0.578085, accuracy: 0.787234  [  250/ 1000]\n",
      "loss: 0.574819, accuracy: 0.786659  [  251/ 1000]\n",
      "loss: 0.578059, accuracy: 0.788959  [  252/ 1000]\n",
      "loss: 0.573174, accuracy: 0.786084  [  253/ 1000]\n",
      "loss: 0.580658, accuracy: 0.789534  [  254/ 1000]\n",
      "loss: 0.572358, accuracy: 0.785509  [  255/ 1000]\n",
      "loss: 0.594764, accuracy: 0.785509  [  256/ 1000]\n",
      "loss: 0.592211, accuracy: 0.777458  [  257/ 1000]\n",
      "loss: 0.667098, accuracy: 0.767108  [  258/ 1000]\n",
      "loss: 0.829661, accuracy: 0.759057  [  259/ 1000]\n",
      "loss: 0.722908, accuracy: 0.759632  [  260/ 1000]\n",
      "loss: 0.830596, accuracy: 0.767683  [  261/ 1000]\n",
      "loss: 0.638361, accuracy: 0.782634  [  262/ 1000]\n",
      "loss: 0.597683, accuracy: 0.784934  [  263/ 1000]\n",
      "loss: 0.598982, accuracy: 0.787234  [  264/ 1000]\n",
      "loss: 0.582323, accuracy: 0.786084  [  265/ 1000]\n",
      "loss: 0.585859, accuracy: 0.788384  [  266/ 1000]\n",
      "loss: 0.579245, accuracy: 0.786084  [  267/ 1000]\n",
      "loss: 0.580868, accuracy: 0.787234  [  268/ 1000]\n",
      "loss: 0.576837, accuracy: 0.787809  [  269/ 1000]\n",
      "loss: 0.578318, accuracy: 0.788959  [  270/ 1000]\n",
      "loss: 0.574923, accuracy: 0.787234  [  271/ 1000]\n",
      "loss: 0.577118, accuracy: 0.790684  [  272/ 1000]\n",
      "loss: 0.573230, accuracy: 0.787809  [  273/ 1000]\n",
      "loss: 0.577393, accuracy: 0.790684  [  274/ 1000]\n",
      "loss: 0.571513, accuracy: 0.785509  [  275/ 1000]\n",
      "loss: 0.581465, accuracy: 0.790684  [  276/ 1000]\n",
      "loss: 0.572617, accuracy: 0.784934  [  277/ 1000]\n",
      "loss: 0.603631, accuracy: 0.782634  [  278/ 1000]\n",
      "loss: 0.605219, accuracy: 0.772283  [  279/ 1000]\n",
      "loss: 0.680996, accuracy: 0.765957  [  280/ 1000]\n",
      "loss: 0.837532, accuracy: 0.754457  [  281/ 1000]\n",
      "loss: 0.707278, accuracy: 0.761357  [  282/ 1000]\n",
      "loss: 0.753158, accuracy: 0.773433  [  283/ 1000]\n",
      "loss: 0.626966, accuracy: 0.785509  [  284/ 1000]\n",
      "loss: 0.590912, accuracy: 0.786084  [  285/ 1000]\n",
      "loss: 0.594867, accuracy: 0.787234  [  286/ 1000]\n",
      "loss: 0.579740, accuracy: 0.786659  [  287/ 1000]\n",
      "loss: 0.583810, accuracy: 0.789534  [  288/ 1000]\n",
      "loss: 0.576947, accuracy: 0.787234  [  289/ 1000]\n",
      "loss: 0.579344, accuracy: 0.788959  [  290/ 1000]\n",
      "loss: 0.574725, accuracy: 0.786659  [  291/ 1000]\n",
      "loss: 0.577190, accuracy: 0.788959  [  292/ 1000]\n",
      "loss: 0.572845, accuracy: 0.786659  [  293/ 1000]\n",
      "loss: 0.576616, accuracy: 0.788959  [  294/ 1000]\n",
      "loss: 0.571072, accuracy: 0.785509  [  295/ 1000]\n",
      "loss: 0.578653, accuracy: 0.791834  [  296/ 1000]\n",
      "loss: 0.570186, accuracy: 0.785509  [  297/ 1000]\n",
      "loss: 0.590475, accuracy: 0.790109  [  298/ 1000]\n",
      "loss: 0.585575, accuracy: 0.781484  [  299/ 1000]\n",
      "loss: 0.650270, accuracy: 0.775158  [  300/ 1000]\n",
      "loss: 0.753280, accuracy: 0.765957  [  301/ 1000]\n",
      "loss: 0.700271, accuracy: 0.762507  [  302/ 1000]\n",
      "loss: 0.817182, accuracy: 0.771708  [  303/ 1000]\n",
      "loss: 0.652044, accuracy: 0.776883  [  304/ 1000]\n",
      "loss: 0.606452, accuracy: 0.780909  [  305/ 1000]\n",
      "loss: 0.607523, accuracy: 0.784934  [  306/ 1000]\n",
      "loss: 0.580435, accuracy: 0.787234  [  307/ 1000]\n",
      "loss: 0.589248, accuracy: 0.788959  [  308/ 1000]\n",
      "loss: 0.575871, accuracy: 0.787234  [  309/ 1000]\n",
      "loss: 0.581685, accuracy: 0.788959  [  310/ 1000]\n",
      "loss: 0.573591, accuracy: 0.787234  [  311/ 1000]\n",
      "loss: 0.578540, accuracy: 0.789534  [  312/ 1000]\n",
      "loss: 0.571658, accuracy: 0.786659  [  313/ 1000]\n",
      "loss: 0.577933, accuracy: 0.790684  [  314/ 1000]\n",
      "loss: 0.569995, accuracy: 0.786084  [  315/ 1000]\n",
      "loss: 0.581192, accuracy: 0.792984  [  316/ 1000]\n",
      "loss: 0.571000, accuracy: 0.782634  [  317/ 1000]\n",
      "loss: 0.598583, accuracy: 0.786659  [  318/ 1000]\n",
      "loss: 0.595388, accuracy: 0.773433  [  319/ 1000]\n",
      "loss: 0.667635, accuracy: 0.767683  [  320/ 1000]\n",
      "loss: 0.766841, accuracy: 0.760782  [  321/ 1000]\n",
      "loss: 0.691286, accuracy: 0.765957  [  322/ 1000]\n",
      "loss: 0.648032, accuracy: 0.775733  [  323/ 1000]\n",
      "loss: 0.629062, accuracy: 0.786084  [  324/ 1000]\n",
      "loss: 0.593684, accuracy: 0.785509  [  325/ 1000]\n",
      "loss: 0.599650, accuracy: 0.789534  [  326/ 1000]\n",
      "loss: 0.577175, accuracy: 0.788384  [  327/ 1000]\n",
      "loss: 0.585747, accuracy: 0.788959  [  328/ 1000]\n",
      "loss: 0.573905, accuracy: 0.787809  [  329/ 1000]\n",
      "loss: 0.579914, accuracy: 0.788959  [  330/ 1000]\n",
      "loss: 0.571799, accuracy: 0.787234  [  331/ 1000]\n",
      "loss: 0.577686, accuracy: 0.789534  [  332/ 1000]\n",
      "loss: 0.569974, accuracy: 0.787234  [  333/ 1000]\n",
      "loss: 0.578337, accuracy: 0.790109  [  334/ 1000]\n",
      "loss: 0.568858, accuracy: 0.786084  [  335/ 1000]\n",
      "loss: 0.585464, accuracy: 0.793559  [  336/ 1000]\n",
      "loss: 0.576151, accuracy: 0.784934  [  337/ 1000]\n",
      "loss: 0.621670, accuracy: 0.784934  [  338/ 1000]\n",
      "loss: 0.618379, accuracy: 0.774583  [  339/ 1000]\n",
      "loss: 0.677060, accuracy: 0.767108  [  340/ 1000]\n",
      "loss: 0.760798, accuracy: 0.766532  [  341/ 1000]\n",
      "loss: 0.666177, accuracy: 0.777458  [  342/ 1000]\n",
      "loss: 0.616474, accuracy: 0.778608  [  343/ 1000]\n",
      "loss: 0.619180, accuracy: 0.787234  [  344/ 1000]\n",
      "loss: 0.587923, accuracy: 0.784359  [  345/ 1000]\n",
      "loss: 0.597086, accuracy: 0.790684  [  346/ 1000]\n",
      "loss: 0.575220, accuracy: 0.787234  [  347/ 1000]\n",
      "loss: 0.585573, accuracy: 0.790109  [  348/ 1000]\n",
      "loss: 0.572047, accuracy: 0.786659  [  349/ 1000]\n",
      "loss: 0.580543, accuracy: 0.788959  [  350/ 1000]\n",
      "loss: 0.570082, accuracy: 0.786659  [  351/ 1000]\n",
      "loss: 0.579362, accuracy: 0.789534  [  352/ 1000]\n",
      "loss: 0.568737, accuracy: 0.786084  [  353/ 1000]\n",
      "loss: 0.583005, accuracy: 0.792984  [  354/ 1000]\n",
      "loss: 0.571208, accuracy: 0.787234  [  355/ 1000]\n",
      "loss: 0.602297, accuracy: 0.784934  [  356/ 1000]\n",
      "loss: 0.597349, accuracy: 0.775733  [  357/ 1000]\n",
      "loss: 0.658148, accuracy: 0.771708  [  358/ 1000]\n",
      "loss: 0.697978, accuracy: 0.771133  [  359/ 1000]\n",
      "loss: 0.668999, accuracy: 0.774008  [  360/ 1000]\n",
      "loss: 0.626851, accuracy: 0.777458  [  361/ 1000]\n",
      "loss: 0.632570, accuracy: 0.784934  [  362/ 1000]\n",
      "loss: 0.596956, accuracy: 0.784359  [  363/ 1000]\n",
      "loss: 0.604559, accuracy: 0.788959  [  364/ 1000]\n",
      "loss: 0.577677, accuracy: 0.786084  [  365/ 1000]\n",
      "loss: 0.590291, accuracy: 0.791259  [  366/ 1000]\n",
      "loss: 0.572269, accuracy: 0.786084  [  367/ 1000]\n",
      "loss: 0.583097, accuracy: 0.790109  [  368/ 1000]\n",
      "loss: 0.569964, accuracy: 0.785509  [  369/ 1000]\n",
      "loss: 0.580642, accuracy: 0.789534  [  370/ 1000]\n",
      "loss: 0.568557, accuracy: 0.787234  [  371/ 1000]\n",
      "loss: 0.582841, accuracy: 0.792984  [  372/ 1000]\n",
      "loss: 0.569910, accuracy: 0.786659  [  373/ 1000]\n",
      "loss: 0.596805, accuracy: 0.787809  [  374/ 1000]\n",
      "loss: 0.588957, accuracy: 0.779758  [  375/ 1000]\n",
      "loss: 0.648982, accuracy: 0.775733  [  376/ 1000]\n",
      "loss: 0.639011, accuracy: 0.772858  [  377/ 1000]\n",
      "loss: 0.675861, accuracy: 0.769983  [  378/ 1000]\n",
      "loss: 0.640292, accuracy: 0.775733  [  379/ 1000]\n",
      "loss: 0.641140, accuracy: 0.782059  [  380/ 1000]\n",
      "loss: 0.599206, accuracy: 0.782634  [  381/ 1000]\n",
      "loss: 0.604793, accuracy: 0.788959  [  382/ 1000]\n",
      "loss: 0.576729, accuracy: 0.787234  [  383/ 1000]\n",
      "loss: 0.588001, accuracy: 0.791259  [  384/ 1000]\n",
      "loss: 0.571733, accuracy: 0.790109  [  385/ 1000]\n",
      "loss: 0.580111, accuracy: 0.788384  [  386/ 1000]\n",
      "loss: 0.569556, accuracy: 0.789534  [  387/ 1000]\n",
      "loss: 0.576809, accuracy: 0.788384  [  388/ 1000]\n",
      "loss: 0.567821, accuracy: 0.788959  [  389/ 1000]\n",
      "loss: 0.576601, accuracy: 0.788959  [  390/ 1000]\n",
      "loss: 0.566589, accuracy: 0.788959  [  391/ 1000]\n",
      "loss: 0.581451, accuracy: 0.794135  [  392/ 1000]\n",
      "loss: 0.570134, accuracy: 0.787234  [  393/ 1000]\n",
      "loss: 0.605816, accuracy: 0.785509  [  394/ 1000]\n",
      "loss: 0.601962, accuracy: 0.775158  [  395/ 1000]\n",
      "loss: 0.669006, accuracy: 0.769408  [  396/ 1000]\n",
      "loss: 0.759544, accuracy: 0.763657  [  397/ 1000]\n",
      "loss: 0.679425, accuracy: 0.771708  [  398/ 1000]\n",
      "loss: 0.628205, accuracy: 0.778033  [  399/ 1000]\n",
      "loss: 0.625094, accuracy: 0.788384  [  400/ 1000]\n",
      "loss: 0.588909, accuracy: 0.786084  [  401/ 1000]\n",
      "loss: 0.595827, accuracy: 0.790109  [  402/ 1000]\n",
      "loss: 0.573414, accuracy: 0.790684  [  403/ 1000]\n",
      "loss: 0.582180, accuracy: 0.788959  [  404/ 1000]\n",
      "loss: 0.570460, accuracy: 0.789534  [  405/ 1000]\n",
      "loss: 0.576327, accuracy: 0.788959  [  406/ 1000]\n",
      "loss: 0.568483, accuracy: 0.789534  [  407/ 1000]\n",
      "loss: 0.573917, accuracy: 0.791259  [  408/ 1000]\n",
      "loss: 0.566727, accuracy: 0.788959  [  409/ 1000]\n",
      "loss: 0.573965, accuracy: 0.791259  [  410/ 1000]\n",
      "loss: 0.565306, accuracy: 0.788959  [  411/ 1000]\n",
      "loss: 0.578556, accuracy: 0.793559  [  412/ 1000]\n",
      "loss: 0.567899, accuracy: 0.786659  [  413/ 1000]\n",
      "loss: 0.601690, accuracy: 0.784934  [  414/ 1000]\n",
      "loss: 0.599197, accuracy: 0.775733  [  415/ 1000]\n",
      "loss: 0.669149, accuracy: 0.768833  [  416/ 1000]\n",
      "loss: 0.764833, accuracy: 0.759632  [  417/ 1000]\n",
      "loss: 0.693474, accuracy: 0.766532  [  418/ 1000]\n",
      "loss: 0.643667, accuracy: 0.776883  [  419/ 1000]\n",
      "loss: 0.621870, accuracy: 0.786659  [  420/ 1000]\n",
      "loss: 0.584488, accuracy: 0.787234  [  421/ 1000]\n",
      "loss: 0.591720, accuracy: 0.790684  [  422/ 1000]\n",
      "loss: 0.572750, accuracy: 0.791259  [  423/ 1000]\n",
      "loss: 0.579308, accuracy: 0.789534  [  424/ 1000]\n",
      "loss: 0.570061, accuracy: 0.789534  [  425/ 1000]\n",
      "loss: 0.574118, accuracy: 0.792409  [  426/ 1000]\n",
      "loss: 0.567985, accuracy: 0.788959  [  427/ 1000]\n",
      "loss: 0.571830, accuracy: 0.792409  [  428/ 1000]\n",
      "loss: 0.566135, accuracy: 0.788959  [  429/ 1000]\n",
      "loss: 0.571504, accuracy: 0.791834  [  430/ 1000]\n",
      "loss: 0.564454, accuracy: 0.788384  [  431/ 1000]\n",
      "loss: 0.574482, accuracy: 0.794135  [  432/ 1000]\n",
      "loss: 0.564660, accuracy: 0.786659  [  433/ 1000]\n",
      "loss: 0.589660, accuracy: 0.791834  [  434/ 1000]\n",
      "loss: 0.585035, accuracy: 0.780334  [  435/ 1000]\n",
      "loss: 0.655415, accuracy: 0.771708  [  436/ 1000]\n",
      "loss: 0.757276, accuracy: 0.761932  [  437/ 1000]\n",
      "loss: 0.706481, accuracy: 0.762507  [  438/ 1000]\n",
      "loss: 0.812609, accuracy: 0.771133  [  439/ 1000]\n",
      "loss: 0.639170, accuracy: 0.783784  [  440/ 1000]\n",
      "loss: 0.593348, accuracy: 0.787809  [  441/ 1000]\n",
      "loss: 0.592672, accuracy: 0.789534  [  442/ 1000]\n",
      "loss: 0.573531, accuracy: 0.790684  [  443/ 1000]\n",
      "loss: 0.578669, accuracy: 0.791834  [  444/ 1000]\n",
      "loss: 0.570523, accuracy: 0.788959  [  445/ 1000]\n",
      "loss: 0.573098, accuracy: 0.791834  [  446/ 1000]\n",
      "loss: 0.568169, accuracy: 0.788384  [  447/ 1000]\n",
      "loss: 0.570398, accuracy: 0.790684  [  448/ 1000]\n",
      "loss: 0.566171, accuracy: 0.787234  [  449/ 1000]\n",
      "loss: 0.569307, accuracy: 0.792409  [  450/ 1000]\n",
      "loss: 0.564346, accuracy: 0.787809  [  451/ 1000]\n",
      "loss: 0.570148, accuracy: 0.792409  [  452/ 1000]\n",
      "loss: 0.562815, accuracy: 0.788384  [  453/ 1000]\n",
      "loss: 0.576213, accuracy: 0.796435  [  454/ 1000]\n",
      "loss: 0.567256, accuracy: 0.788384  [  455/ 1000]\n",
      "loss: 0.608684, accuracy: 0.786659  [  456/ 1000]\n",
      "loss: 0.609042, accuracy: 0.775733  [  457/ 1000]\n",
      "loss: 0.677834, accuracy: 0.767108  [  458/ 1000]\n",
      "loss: 0.820641, accuracy: 0.758482  [  459/ 1000]\n",
      "loss: 0.689448, accuracy: 0.767108  [  460/ 1000]\n",
      "loss: 0.632699, accuracy: 0.779183  [  461/ 1000]\n",
      "loss: 0.617778, accuracy: 0.788384  [  462/ 1000]\n",
      "loss: 0.581538, accuracy: 0.787809  [  463/ 1000]\n",
      "loss: 0.589166, accuracy: 0.793559  [  464/ 1000]\n",
      "loss: 0.570776, accuracy: 0.790684  [  465/ 1000]\n",
      "loss: 0.577566, accuracy: 0.791259  [  466/ 1000]\n",
      "loss: 0.567988, accuracy: 0.790109  [  467/ 1000]\n",
      "loss: 0.572663, accuracy: 0.790109  [  468/ 1000]\n",
      "loss: 0.565814, accuracy: 0.789534  [  469/ 1000]\n",
      "loss: 0.570683, accuracy: 0.791834  [  470/ 1000]\n",
      "loss: 0.563893, accuracy: 0.788959  [  471/ 1000]\n",
      "loss: 0.571179, accuracy: 0.792409  [  472/ 1000]\n",
      "loss: 0.562502, accuracy: 0.787809  [  473/ 1000]\n",
      "loss: 0.576880, accuracy: 0.796435  [  474/ 1000]\n",
      "loss: 0.566921, accuracy: 0.787234  [  475/ 1000]\n",
      "loss: 0.606207, accuracy: 0.787809  [  476/ 1000]\n",
      "loss: 0.603723, accuracy: 0.775733  [  477/ 1000]\n",
      "loss: 0.667215, accuracy: 0.770558  [  478/ 1000]\n",
      "loss: 0.756196, accuracy: 0.764232  [  479/ 1000]\n",
      "loss: 0.673137, accuracy: 0.774583  [  480/ 1000]\n",
      "loss: 0.621350, accuracy: 0.780909  [  481/ 1000]\n",
      "loss: 0.618823, accuracy: 0.787234  [  482/ 1000]\n",
      "loss: 0.584108, accuracy: 0.787234  [  483/ 1000]\n",
      "loss: 0.591607, accuracy: 0.792409  [  484/ 1000]\n",
      "loss: 0.569634, accuracy: 0.790109  [  485/ 1000]\n",
      "loss: 0.579222, accuracy: 0.791834  [  486/ 1000]\n",
      "loss: 0.566513, accuracy: 0.788959  [  487/ 1000]\n",
      "loss: 0.574064, accuracy: 0.791259  [  488/ 1000]\n",
      "loss: 0.564415, accuracy: 0.788384  [  489/ 1000]\n",
      "loss: 0.572534, accuracy: 0.792409  [  490/ 1000]\n",
      "loss: 0.562801, accuracy: 0.786659  [  491/ 1000]\n",
      "loss: 0.574847, accuracy: 0.793559  [  492/ 1000]\n",
      "loss: 0.563308, accuracy: 0.787234  [  493/ 1000]\n",
      "loss: 0.588124, accuracy: 0.791834  [  494/ 1000]\n",
      "loss: 0.580409, accuracy: 0.782059  [  495/ 1000]\n",
      "loss: 0.641145, accuracy: 0.776308  [  496/ 1000]\n",
      "loss: 0.634344, accuracy: 0.768833  [  497/ 1000]\n",
      "loss: 0.679289, accuracy: 0.769983  [  498/ 1000]\n",
      "loss: 0.696478, accuracy: 0.772858  [  499/ 1000]\n",
      "loss: 0.637576, accuracy: 0.781484  [  500/ 1000]\n",
      "loss: 0.593772, accuracy: 0.784934  [  501/ 1000]\n",
      "loss: 0.597475, accuracy: 0.790109  [  502/ 1000]\n",
      "loss: 0.570879, accuracy: 0.788959  [  503/ 1000]\n",
      "loss: 0.581120, accuracy: 0.792409  [  504/ 1000]\n",
      "loss: 0.566724, accuracy: 0.789534  [  505/ 1000]\n",
      "loss: 0.574248, accuracy: 0.791259  [  506/ 1000]\n",
      "loss: 0.564479, accuracy: 0.788384  [  507/ 1000]\n",
      "loss: 0.571549, accuracy: 0.791259  [  508/ 1000]\n",
      "loss: 0.562655, accuracy: 0.788384  [  509/ 1000]\n",
      "loss: 0.571966, accuracy: 0.792409  [  510/ 1000]\n",
      "loss: 0.561603, accuracy: 0.788384  [  511/ 1000]\n",
      "loss: 0.578247, accuracy: 0.795285  [  512/ 1000]\n",
      "loss: 0.567536, accuracy: 0.788959  [  513/ 1000]\n",
      "loss: 0.609610, accuracy: 0.787809  [  514/ 1000]\n",
      "loss: 0.604224, accuracy: 0.775158  [  515/ 1000]\n",
      "loss: 0.664045, accuracy: 0.772283  [  516/ 1000]\n",
      "loss: 0.747392, accuracy: 0.765382  [  517/ 1000]\n",
      "loss: 0.662624, accuracy: 0.775733  [  518/ 1000]\n",
      "loss: 0.612159, accuracy: 0.778608  [  519/ 1000]\n",
      "loss: 0.614534, accuracy: 0.789534  [  520/ 1000]\n",
      "loss: 0.581098, accuracy: 0.788384  [  521/ 1000]\n",
      "loss: 0.593137, accuracy: 0.790684  [  522/ 1000]\n",
      "loss: 0.568810, accuracy: 0.787809  [  523/ 1000]\n",
      "loss: 0.580979, accuracy: 0.794135  [  524/ 1000]\n",
      "loss: 0.565053, accuracy: 0.788959  [  525/ 1000]\n",
      "loss: 0.575589, accuracy: 0.793559  [  526/ 1000]\n",
      "loss: 0.563043, accuracy: 0.790109  [  527/ 1000]\n",
      "loss: 0.574486, accuracy: 0.792409  [  528/ 1000]\n",
      "loss: 0.562000, accuracy: 0.788384  [  529/ 1000]\n",
      "loss: 0.578770, accuracy: 0.795860  [  530/ 1000]\n",
      "loss: 0.566003, accuracy: 0.789534  [  531/ 1000]\n",
      "loss: 0.600954, accuracy: 0.787809  [  532/ 1000]\n",
      "loss: 0.592892, accuracy: 0.778033  [  533/ 1000]\n",
      "loss: 0.650663, accuracy: 0.772283  [  534/ 1000]\n",
      "loss: 0.634778, accuracy: 0.769983  [  535/ 1000]\n",
      "loss: 0.664612, accuracy: 0.776308  [  536/ 1000]\n",
      "loss: 0.619732, accuracy: 0.779758  [  537/ 1000]\n",
      "loss: 0.624748, accuracy: 0.787809  [  538/ 1000]\n",
      "loss: 0.586843, accuracy: 0.786084  [  539/ 1000]\n",
      "loss: 0.593572, accuracy: 0.790684  [  540/ 1000]\n",
      "loss: 0.568457, accuracy: 0.790684  [  541/ 1000]\n",
      "loss: 0.579382, accuracy: 0.792984  [  542/ 1000]\n",
      "loss: 0.564857, accuracy: 0.790109  [  543/ 1000]\n",
      "loss: 0.573148, accuracy: 0.791259  [  544/ 1000]\n",
      "loss: 0.562781, accuracy: 0.790109  [  545/ 1000]\n",
      "loss: 0.570850, accuracy: 0.792409  [  546/ 1000]\n",
      "loss: 0.561125, accuracy: 0.789534  [  547/ 1000]\n",
      "loss: 0.571897, accuracy: 0.792984  [  548/ 1000]\n",
      "loss: 0.560557, accuracy: 0.788959  [  549/ 1000]\n",
      "loss: 0.580302, accuracy: 0.792984  [  550/ 1000]\n",
      "loss: 0.569872, accuracy: 0.787234  [  551/ 1000]\n",
      "loss: 0.619264, accuracy: 0.784359  [  552/ 1000]\n",
      "loss: 0.611579, accuracy: 0.774008  [  553/ 1000]\n",
      "loss: 0.669343, accuracy: 0.773433  [  554/ 1000]\n",
      "loss: 0.747066, accuracy: 0.765957  [  555/ 1000]\n",
      "loss: 0.651579, accuracy: 0.782634  [  556/ 1000]\n",
      "loss: 0.600836, accuracy: 0.783209  [  557/ 1000]\n",
      "loss: 0.604389, accuracy: 0.791834  [  558/ 1000]\n",
      "loss: 0.573140, accuracy: 0.789534  [  559/ 1000]\n",
      "loss: 0.584718, accuracy: 0.792984  [  560/ 1000]\n",
      "loss: 0.565563, accuracy: 0.791259  [  561/ 1000]\n",
      "loss: 0.575154, accuracy: 0.792409  [  562/ 1000]\n",
      "loss: 0.563042, accuracy: 0.790109  [  563/ 1000]\n",
      "loss: 0.571171, accuracy: 0.791259  [  564/ 1000]\n",
      "loss: 0.561186, accuracy: 0.790109  [  565/ 1000]\n",
      "loss: 0.570541, accuracy: 0.792984  [  566/ 1000]\n",
      "loss: 0.559904, accuracy: 0.787809  [  567/ 1000]\n",
      "loss: 0.574499, accuracy: 0.795860  [  568/ 1000]\n",
      "loss: 0.562391, accuracy: 0.788384  [  569/ 1000]\n",
      "loss: 0.594963, accuracy: 0.787809  [  570/ 1000]\n",
      "loss: 0.588461, accuracy: 0.778033  [  571/ 1000]\n",
      "loss: 0.659397, accuracy: 0.771133  [  572/ 1000]\n",
      "loss: 0.751665, accuracy: 0.763082  [  573/ 1000]\n",
      "loss: 0.683549, accuracy: 0.772283  [  574/ 1000]\n",
      "loss: 0.634633, accuracy: 0.777458  [  575/ 1000]\n",
      "loss: 0.624054, accuracy: 0.787809  [  576/ 1000]\n",
      "loss: 0.582714, accuracy: 0.788384  [  577/ 1000]\n",
      "loss: 0.587477, accuracy: 0.792984  [  578/ 1000]\n",
      "loss: 0.567251, accuracy: 0.790684  [  579/ 1000]\n",
      "loss: 0.574212, accuracy: 0.791259  [  580/ 1000]\n",
      "loss: 0.564502, accuracy: 0.790109  [  581/ 1000]\n",
      "loss: 0.568754, accuracy: 0.790109  [  582/ 1000]\n",
      "loss: 0.562381, accuracy: 0.789534  [  583/ 1000]\n",
      "loss: 0.566295, accuracy: 0.791259  [  584/ 1000]\n",
      "loss: 0.560493, accuracy: 0.788959  [  585/ 1000]\n",
      "loss: 0.565786, accuracy: 0.792409  [  586/ 1000]\n",
      "loss: 0.558787, accuracy: 0.788959  [  587/ 1000]\n",
      "loss: 0.568139, accuracy: 0.794135  [  588/ 1000]\n",
      "loss: 0.558313, accuracy: 0.787809  [  589/ 1000]\n",
      "loss: 0.579904, accuracy: 0.793559  [  590/ 1000]\n",
      "loss: 0.572252, accuracy: 0.783784  [  591/ 1000]\n",
      "loss: 0.634664, accuracy: 0.776308  [  592/ 1000]\n",
      "loss: 0.634295, accuracy: 0.765382  [  593/ 1000]\n",
      "loss: 0.694081, accuracy: 0.769983  [  594/ 1000]\n",
      "loss: 0.815739, accuracy: 0.761932  [  595/ 1000]\n",
      "loss: 0.654794, accuracy: 0.781484  [  596/ 1000]\n",
      "loss: 0.595600, accuracy: 0.784934  [  597/ 1000]\n",
      "loss: 0.593080, accuracy: 0.791834  [  598/ 1000]\n",
      "loss: 0.568381, accuracy: 0.791834  [  599/ 1000]\n",
      "loss: 0.575361, accuracy: 0.792409  [  600/ 1000]\n",
      "loss: 0.565103, accuracy: 0.790109  [  601/ 1000]\n",
      "loss: 0.568720, accuracy: 0.790684  [  602/ 1000]\n",
      "loss: 0.562697, accuracy: 0.789534  [  603/ 1000]\n",
      "loss: 0.565618, accuracy: 0.791259  [  604/ 1000]\n",
      "loss: 0.560639, accuracy: 0.789534  [  605/ 1000]\n",
      "loss: 0.564375, accuracy: 0.792409  [  606/ 1000]\n",
      "loss: 0.558781, accuracy: 0.788959  [  607/ 1000]\n",
      "loss: 0.565154, accuracy: 0.793559  [  608/ 1000]\n",
      "loss: 0.557278, accuracy: 0.788959  [  609/ 1000]\n",
      "loss: 0.570738, accuracy: 0.795860  [  610/ 1000]\n",
      "loss: 0.560847, accuracy: 0.788959  [  611/ 1000]\n",
      "loss: 0.600094, accuracy: 0.788959  [  612/ 1000]\n",
      "loss: 0.598227, accuracy: 0.775158  [  613/ 1000]\n",
      "loss: 0.667464, accuracy: 0.770558  [  614/ 1000]\n",
      "loss: 0.761578, accuracy: 0.759057  [  615/ 1000]\n",
      "loss: 0.689370, accuracy: 0.771133  [  616/ 1000]\n",
      "loss: 0.634811, accuracy: 0.778033  [  617/ 1000]\n",
      "loss: 0.614093, accuracy: 0.788959  [  618/ 1000]\n",
      "loss: 0.575670, accuracy: 0.788384  [  619/ 1000]\n",
      "loss: 0.583105, accuracy: 0.792409  [  620/ 1000]\n",
      "loss: 0.565684, accuracy: 0.790684  [  621/ 1000]\n",
      "loss: 0.571822, accuracy: 0.792409  [  622/ 1000]\n",
      "loss: 0.562904, accuracy: 0.790109  [  623/ 1000]\n",
      "loss: 0.567034, accuracy: 0.789534  [  624/ 1000]\n",
      "loss: 0.560660, accuracy: 0.789534  [  625/ 1000]\n",
      "loss: 0.564965, accuracy: 0.791834  [  626/ 1000]\n",
      "loss: 0.558693, accuracy: 0.788959  [  627/ 1000]\n",
      "loss: 0.565036, accuracy: 0.793559  [  628/ 1000]\n",
      "loss: 0.557063, accuracy: 0.788959  [  629/ 1000]\n",
      "loss: 0.568991, accuracy: 0.795285  [  630/ 1000]\n",
      "loss: 0.558469, accuracy: 0.789534  [  631/ 1000]\n",
      "loss: 0.588830, accuracy: 0.790109  [  632/ 1000]\n",
      "loss: 0.584065, accuracy: 0.778033  [  633/ 1000]\n",
      "loss: 0.660209, accuracy: 0.769408  [  634/ 1000]\n",
      "loss: 0.760559, accuracy: 0.758482  [  635/ 1000]\n",
      "loss: 0.702307, accuracy: 0.764807  [  636/ 1000]\n",
      "loss: 0.748309, accuracy: 0.771708  [  637/ 1000]\n",
      "loss: 0.622174, accuracy: 0.786084  [  638/ 1000]\n",
      "loss: 0.578953, accuracy: 0.788959  [  639/ 1000]\n",
      "loss: 0.584339, accuracy: 0.792409  [  640/ 1000]\n",
      "loss: 0.566143, accuracy: 0.791259  [  641/ 1000]\n",
      "loss: 0.571772, accuracy: 0.792409  [  642/ 1000]\n",
      "loss: 0.563174, accuracy: 0.790109  [  643/ 1000]\n",
      "loss: 0.566554, accuracy: 0.790684  [  644/ 1000]\n",
      "loss: 0.560775, accuracy: 0.789534  [  645/ 1000]\n",
      "loss: 0.564100, accuracy: 0.791259  [  646/ 1000]\n",
      "loss: 0.558704, accuracy: 0.788959  [  647/ 1000]\n",
      "loss: 0.563516, accuracy: 0.793559  [  648/ 1000]\n",
      "loss: 0.556865, accuracy: 0.789534  [  649/ 1000]\n",
      "loss: 0.565689, accuracy: 0.794135  [  650/ 1000]\n",
      "loss: 0.556173, accuracy: 0.788384  [  651/ 1000]\n",
      "loss: 0.576440, accuracy: 0.794710  [  652/ 1000]\n",
      "loss: 0.568242, accuracy: 0.786084  [  653/ 1000]\n",
      "loss: 0.627022, accuracy: 0.779758  [  654/ 1000]\n",
      "loss: 0.624210, accuracy: 0.768258  [  655/ 1000]\n",
      "loss: 0.684526, accuracy: 0.769408  [  656/ 1000]\n",
      "loss: 0.760222, accuracy: 0.762507  [  657/ 1000]\n",
      "loss: 0.656357, accuracy: 0.780909  [  658/ 1000]\n",
      "loss: 0.597063, accuracy: 0.784359  [  659/ 1000]\n",
      "loss: 0.595565, accuracy: 0.791834  [  660/ 1000]\n",
      "loss: 0.566837, accuracy: 0.790684  [  661/ 1000]\n",
      "loss: 0.576004, accuracy: 0.792984  [  662/ 1000]\n",
      "loss: 0.562603, accuracy: 0.791259  [  663/ 1000]\n",
      "loss: 0.568616, accuracy: 0.792984  [  664/ 1000]\n",
      "loss: 0.560122, accuracy: 0.790109  [  665/ 1000]\n",
      "loss: 0.565453, accuracy: 0.791259  [  666/ 1000]\n",
      "loss: 0.558042, accuracy: 0.789534  [  667/ 1000]\n",
      "loss: 0.564854, accuracy: 0.793559  [  668/ 1000]\n",
      "loss: 0.556340, accuracy: 0.788959  [  669/ 1000]\n",
      "loss: 0.567813, accuracy: 0.795860  [  670/ 1000]\n",
      "loss: 0.556832, accuracy: 0.788959  [  671/ 1000]\n",
      "loss: 0.582640, accuracy: 0.791834  [  672/ 1000]\n",
      "loss: 0.574965, accuracy: 0.782059  [  673/ 1000]\n",
      "loss: 0.640865, accuracy: 0.775158  [  674/ 1000]\n",
      "loss: 0.637629, accuracy: 0.764232  [  675/ 1000]\n",
      "loss: 0.679516, accuracy: 0.772283  [  676/ 1000]\n",
      "loss: 0.740718, accuracy: 0.768833  [  677/ 1000]\n",
      "loss: 0.630550, accuracy: 0.782634  [  678/ 1000]\n",
      "loss: 0.585181, accuracy: 0.786659  [  679/ 1000]\n",
      "loss: 0.587762, accuracy: 0.793559  [  680/ 1000]\n",
      "loss: 0.564203, accuracy: 0.789534  [  681/ 1000]\n",
      "loss: 0.573031, accuracy: 0.792984  [  682/ 1000]\n",
      "loss: 0.560947, accuracy: 0.790109  [  683/ 1000]\n",
      "loss: 0.567284, accuracy: 0.792409  [  684/ 1000]\n",
      "loss: 0.558651, accuracy: 0.789534  [  685/ 1000]\n",
      "loss: 0.565097, accuracy: 0.792409  [  686/ 1000]\n",
      "loss: 0.556734, accuracy: 0.789534  [  687/ 1000]\n",
      "loss: 0.565789, accuracy: 0.794135  [  688/ 1000]\n",
      "loss: 0.555591, accuracy: 0.788959  [  689/ 1000]\n",
      "loss: 0.572228, accuracy: 0.795860  [  690/ 1000]\n",
      "loss: 0.561212, accuracy: 0.788959  [  691/ 1000]\n",
      "loss: 0.603328, accuracy: 0.787809  [  692/ 1000]\n",
      "loss: 0.596890, accuracy: 0.774583  [  693/ 1000]\n",
      "loss: 0.658171, accuracy: 0.773433  [  694/ 1000]\n",
      "loss: 0.741332, accuracy: 0.763657  [  695/ 1000]\n",
      "loss: 0.659565, accuracy: 0.776308  [  696/ 1000]\n",
      "loss: 0.607592, accuracy: 0.779758  [  697/ 1000]\n",
      "loss: 0.609459, accuracy: 0.790684  [  698/ 1000]\n",
      "loss: 0.574444, accuracy: 0.788384  [  699/ 1000]\n",
      "loss: 0.586091, accuracy: 0.792984  [  700/ 1000]\n",
      "loss: 0.562555, accuracy: 0.791259  [  701/ 1000]\n",
      "loss: 0.574354, accuracy: 0.794710  [  702/ 1000]\n",
      "loss: 0.559254, accuracy: 0.790109  [  703/ 1000]\n",
      "loss: 0.569517, accuracy: 0.794710  [  704/ 1000]\n",
      "loss: 0.557270, accuracy: 0.789534  [  705/ 1000]\n",
      "loss: 0.568847, accuracy: 0.794710  [  706/ 1000]\n",
      "loss: 0.556261, accuracy: 0.789534  [  707/ 1000]\n",
      "loss: 0.573699, accuracy: 0.794710  [  708/ 1000]\n",
      "loss: 0.560591, accuracy: 0.788384  [  709/ 1000]\n",
      "loss: 0.596693, accuracy: 0.790109  [  710/ 1000]\n",
      "loss: 0.587018, accuracy: 0.776883  [  711/ 1000]\n",
      "loss: 0.645376, accuracy: 0.774008  [  712/ 1000]\n",
      "loss: 0.627859, accuracy: 0.768833  [  713/ 1000]\n",
      "loss: 0.660421, accuracy: 0.776883  [  714/ 1000]\n",
      "loss: 0.614213, accuracy: 0.780334  [  715/ 1000]\n",
      "loss: 0.619229, accuracy: 0.788959  [  716/ 1000]\n",
      "loss: 0.579720, accuracy: 0.787234  [  717/ 1000]\n",
      "loss: 0.586263, accuracy: 0.792984  [  718/ 1000]\n",
      "loss: 0.562442, accuracy: 0.790684  [  719/ 1000]\n",
      "loss: 0.572923, accuracy: 0.794135  [  720/ 1000]\n",
      "loss: 0.559294, accuracy: 0.790109  [  721/ 1000]\n",
      "loss: 0.567403, accuracy: 0.793559  [  722/ 1000]\n",
      "loss: 0.557208, accuracy: 0.790109  [  723/ 1000]\n",
      "loss: 0.565606, accuracy: 0.794135  [  724/ 1000]\n",
      "loss: 0.555557, accuracy: 0.789534  [  725/ 1000]\n",
      "loss: 0.567311, accuracy: 0.794710  [  726/ 1000]\n",
      "loss: 0.555365, accuracy: 0.790684  [  727/ 1000]\n",
      "loss: 0.577579, accuracy: 0.791834  [  728/ 1000]\n",
      "loss: 0.566739, accuracy: 0.785509  [  729/ 1000]\n",
      "loss: 0.620681, accuracy: 0.782059  [  730/ 1000]\n",
      "loss: 0.610480, accuracy: 0.771708  [  731/ 1000]\n",
      "loss: 0.667601, accuracy: 0.772858  [  732/ 1000]\n",
      "loss: 0.692102, accuracy: 0.767108  [  733/ 1000]\n",
      "loss: 0.646551, accuracy: 0.782634  [  734/ 1000]\n",
      "loss: 0.592893, accuracy: 0.783784  [  735/ 1000]\n",
      "loss: 0.595954, accuracy: 0.791259  [  736/ 1000]\n",
      "loss: 0.565473, accuracy: 0.789534  [  737/ 1000]\n",
      "loss: 0.576662, accuracy: 0.794135  [  738/ 1000]\n",
      "loss: 0.560083, accuracy: 0.789534  [  739/ 1000]\n",
      "loss: 0.568433, accuracy: 0.792984  [  740/ 1000]\n",
      "loss: 0.557735, accuracy: 0.790109  [  741/ 1000]\n",
      "loss: 0.565122, accuracy: 0.792984  [  742/ 1000]\n",
      "loss: 0.555839, accuracy: 0.789534  [  743/ 1000]\n",
      "loss: 0.564852, accuracy: 0.794135  [  744/ 1000]\n",
      "loss: 0.554480, accuracy: 0.789534  [  745/ 1000]\n",
      "loss: 0.569054, accuracy: 0.794710  [  746/ 1000]\n",
      "loss: 0.556826, accuracy: 0.787234  [  747/ 1000]\n",
      "loss: 0.589365, accuracy: 0.790109  [  748/ 1000]\n",
      "loss: 0.581503, accuracy: 0.778033  [  749/ 1000]\n",
      "loss: 0.653349, accuracy: 0.771708  [  750/ 1000]\n",
      "loss: 0.745486, accuracy: 0.761357  [  751/ 1000]\n",
      "loss: 0.680509, accuracy: 0.774583  [  752/ 1000]\n",
      "loss: 0.631834, accuracy: 0.775158  [  753/ 1000]\n",
      "loss: 0.617486, accuracy: 0.788959  [  754/ 1000]\n",
      "loss: 0.575417, accuracy: 0.788384  [  755/ 1000]\n",
      "loss: 0.583118, accuracy: 0.793559  [  756/ 1000]\n",
      "loss: 0.561925, accuracy: 0.790684  [  757/ 1000]\n",
      "loss: 0.569851, accuracy: 0.792984  [  758/ 1000]\n",
      "loss: 0.559121, accuracy: 0.790109  [  759/ 1000]\n",
      "loss: 0.564589, accuracy: 0.790684  [  760/ 1000]\n",
      "loss: 0.556926, accuracy: 0.789534  [  761/ 1000]\n",
      "loss: 0.562427, accuracy: 0.790684  [  762/ 1000]\n",
      "loss: 0.555010, accuracy: 0.789534  [  763/ 1000]\n",
      "loss: 0.562669, accuracy: 0.794135  [  764/ 1000]\n",
      "loss: 0.553536, accuracy: 0.788384  [  765/ 1000]\n",
      "loss: 0.567172, accuracy: 0.794710  [  766/ 1000]\n",
      "loss: 0.555720, accuracy: 0.787809  [  767/ 1000]\n",
      "loss: 0.588466, accuracy: 0.790109  [  768/ 1000]\n",
      "loss: 0.581782, accuracy: 0.776308  [  769/ 1000]\n",
      "loss: 0.657616, accuracy: 0.769408  [  770/ 1000]\n",
      "loss: 0.754149, accuracy: 0.760207  [  771/ 1000]\n",
      "loss: 0.691973, accuracy: 0.770558  [  772/ 1000]\n",
      "loss: 0.639798, accuracy: 0.772858  [  773/ 1000]\n",
      "loss: 0.615212, accuracy: 0.787809  [  774/ 1000]\n",
      "loss: 0.572639, accuracy: 0.788959  [  775/ 1000]\n",
      "loss: 0.579480, accuracy: 0.791834  [  776/ 1000]\n",
      "loss: 0.562158, accuracy: 0.791259  [  777/ 1000]\n",
      "loss: 0.567811, accuracy: 0.791259  [  778/ 1000]\n",
      "loss: 0.559352, accuracy: 0.790684  [  779/ 1000]\n",
      "loss: 0.562954, accuracy: 0.790109  [  780/ 1000]\n",
      "loss: 0.557022, accuracy: 0.788959  [  781/ 1000]\n",
      "loss: 0.560698, accuracy: 0.790109  [  782/ 1000]\n",
      "loss: 0.554992, accuracy: 0.788959  [  783/ 1000]\n",
      "loss: 0.560334, accuracy: 0.792984  [  784/ 1000]\n",
      "loss: 0.553200, accuracy: 0.789534  [  785/ 1000]\n",
      "loss: 0.562907, accuracy: 0.794135  [  786/ 1000]\n",
      "loss: 0.552763, accuracy: 0.789534  [  787/ 1000]\n",
      "loss: 0.574904, accuracy: 0.791834  [  788/ 1000]\n",
      "loss: 0.566001, accuracy: 0.784934  [  789/ 1000]\n",
      "loss: 0.627503, accuracy: 0.778608  [  790/ 1000]\n",
      "loss: 0.624437, accuracy: 0.767108  [  791/ 1000]\n",
      "loss: 0.685571, accuracy: 0.769408  [  792/ 1000]\n",
      "loss: 0.758903, accuracy: 0.763657  [  793/ 1000]\n",
      "loss: 0.651818, accuracy: 0.782059  [  794/ 1000]\n",
      "loss: 0.590270, accuracy: 0.784359  [  795/ 1000]\n",
      "loss: 0.587831, accuracy: 0.792984  [  796/ 1000]\n",
      "loss: 0.562754, accuracy: 0.791834  [  797/ 1000]\n",
      "loss: 0.570299, accuracy: 0.791834  [  798/ 1000]\n",
      "loss: 0.559490, accuracy: 0.790684  [  799/ 1000]\n",
      "loss: 0.563938, accuracy: 0.790109  [  800/ 1000]\n",
      "loss: 0.557007, accuracy: 0.788959  [  801/ 1000]\n",
      "loss: 0.561049, accuracy: 0.790109  [  802/ 1000]\n",
      "loss: 0.554875, accuracy: 0.788959  [  803/ 1000]\n",
      "loss: 0.560285, accuracy: 0.791259  [  804/ 1000]\n",
      "loss: 0.553016, accuracy: 0.789534  [  805/ 1000]\n",
      "loss: 0.562316, accuracy: 0.794135  [  806/ 1000]\n",
      "loss: 0.552238, accuracy: 0.789534  [  807/ 1000]\n",
      "loss: 0.572262, accuracy: 0.795860  [  808/ 1000]\n",
      "loss: 0.562358, accuracy: 0.786659  [  809/ 1000]\n",
      "loss: 0.616920, accuracy: 0.780909  [  810/ 1000]\n",
      "loss: 0.610853, accuracy: 0.771133  [  811/ 1000]\n",
      "loss: 0.674630, accuracy: 0.770558  [  812/ 1000]\n",
      "loss: 0.752976, accuracy: 0.763657  [  813/ 1000]\n",
      "loss: 0.655291, accuracy: 0.779758  [  814/ 1000]\n",
      "loss: 0.594701, accuracy: 0.783209  [  815/ 1000]\n",
      "loss: 0.593447, accuracy: 0.792409  [  816/ 1000]\n",
      "loss: 0.563208, accuracy: 0.790684  [  817/ 1000]\n",
      "loss: 0.573045, accuracy: 0.792409  [  818/ 1000]\n",
      "loss: 0.558666, accuracy: 0.790684  [  819/ 1000]\n",
      "loss: 0.565391, accuracy: 0.791834  [  820/ 1000]\n",
      "loss: 0.556182, accuracy: 0.790109  [  821/ 1000]\n",
      "loss: 0.562241, accuracy: 0.790109  [  822/ 1000]\n",
      "loss: 0.554099, accuracy: 0.789534  [  823/ 1000]\n",
      "loss: 0.561822, accuracy: 0.794135  [  824/ 1000]\n",
      "loss: 0.552465, accuracy: 0.789534  [  825/ 1000]\n",
      "loss: 0.565268, accuracy: 0.795860  [  826/ 1000]\n",
      "loss: 0.553470, accuracy: 0.789534  [  827/ 1000]\n",
      "loss: 0.581237, accuracy: 0.790684  [  828/ 1000]\n",
      "loss: 0.572057, accuracy: 0.779183  [  829/ 1000]\n",
      "loss: 0.638392, accuracy: 0.775158  [  830/ 1000]\n",
      "loss: 0.633235, accuracy: 0.765957  [  831/ 1000]\n",
      "loss: 0.681993, accuracy: 0.772858  [  832/ 1000]\n",
      "loss: 0.741294, accuracy: 0.768833  [  833/ 1000]\n",
      "loss: 0.629134, accuracy: 0.784359  [  834/ 1000]\n",
      "loss: 0.579760, accuracy: 0.787809  [  835/ 1000]\n",
      "loss: 0.581215, accuracy: 0.792984  [  836/ 1000]\n",
      "loss: 0.560722, accuracy: 0.791259  [  837/ 1000]\n",
      "loss: 0.567666, accuracy: 0.791834  [  838/ 1000]\n",
      "loss: 0.557793, accuracy: 0.790109  [  839/ 1000]\n",
      "loss: 0.562388, accuracy: 0.790109  [  840/ 1000]\n",
      "loss: 0.555429, accuracy: 0.788959  [  841/ 1000]\n",
      "loss: 0.560124, accuracy: 0.789534  [  842/ 1000]\n",
      "loss: 0.553390, accuracy: 0.788959  [  843/ 1000]\n",
      "loss: 0.560107, accuracy: 0.794135  [  844/ 1000]\n",
      "loss: 0.551714, accuracy: 0.789534  [  845/ 1000]\n",
      "loss: 0.563848, accuracy: 0.795285  [  846/ 1000]\n",
      "loss: 0.552621, accuracy: 0.789534  [  847/ 1000]\n",
      "loss: 0.580928, accuracy: 0.790684  [  848/ 1000]\n",
      "loss: 0.572696, accuracy: 0.779183  [  849/ 1000]\n",
      "loss: 0.643431, accuracy: 0.772858  [  850/ 1000]\n",
      "loss: 0.738732, accuracy: 0.761932  [  851/ 1000]\n",
      "loss: 0.683009, accuracy: 0.773433  [  852/ 1000]\n",
      "loss: 0.689380, accuracy: 0.769983  [  853/ 1000]\n",
      "loss: 0.623126, accuracy: 0.783784  [  854/ 1000]\n",
      "loss: 0.576618, accuracy: 0.788959  [  855/ 1000]\n",
      "loss: 0.580623, accuracy: 0.793559  [  856/ 1000]\n",
      "loss: 0.560036, accuracy: 0.790684  [  857/ 1000]\n",
      "loss: 0.567360, accuracy: 0.792409  [  858/ 1000]\n",
      "loss: 0.557104, accuracy: 0.790109  [  859/ 1000]\n",
      "loss: 0.562228, accuracy: 0.790109  [  860/ 1000]\n",
      "loss: 0.554747, accuracy: 0.788959  [  861/ 1000]\n",
      "loss: 0.560158, accuracy: 0.789534  [  862/ 1000]\n",
      "loss: 0.552729, accuracy: 0.789534  [  863/ 1000]\n",
      "loss: 0.560556, accuracy: 0.794135  [  864/ 1000]\n",
      "loss: 0.551229, accuracy: 0.789534  [  865/ 1000]\n",
      "loss: 0.565463, accuracy: 0.794710  [  866/ 1000]\n",
      "loss: 0.553783, accuracy: 0.788384  [  867/ 1000]\n",
      "loss: 0.587282, accuracy: 0.790109  [  868/ 1000]\n",
      "loss: 0.579551, accuracy: 0.777458  [  869/ 1000]\n",
      "loss: 0.654184, accuracy: 0.771133  [  870/ 1000]\n",
      "loss: 0.748001, accuracy: 0.759057  [  871/ 1000]\n",
      "loss: 0.686166, accuracy: 0.771133  [  872/ 1000]\n",
      "loss: 0.634667, accuracy: 0.772283  [  873/ 1000]\n",
      "loss: 0.615598, accuracy: 0.788384  [  874/ 1000]\n",
      "loss: 0.571639, accuracy: 0.787809  [  875/ 1000]\n",
      "loss: 0.578932, accuracy: 0.793559  [  876/ 1000]\n",
      "loss: 0.559585, accuracy: 0.790684  [  877/ 1000]\n",
      "loss: 0.566557, accuracy: 0.792984  [  878/ 1000]\n",
      "loss: 0.556736, accuracy: 0.790109  [  879/ 1000]\n",
      "loss: 0.561684, accuracy: 0.790109  [  880/ 1000]\n",
      "loss: 0.554386, accuracy: 0.788959  [  881/ 1000]\n",
      "loss: 0.559701, accuracy: 0.789534  [  882/ 1000]\n",
      "loss: 0.552365, accuracy: 0.790109  [  883/ 1000]\n",
      "loss: 0.560113, accuracy: 0.794135  [  884/ 1000]\n",
      "loss: 0.550850, accuracy: 0.789534  [  885/ 1000]\n",
      "loss: 0.564889, accuracy: 0.794710  [  886/ 1000]\n",
      "loss: 0.553152, accuracy: 0.788959  [  887/ 1000]\n",
      "loss: 0.585588, accuracy: 0.789534  [  888/ 1000]\n",
      "loss: 0.577267, accuracy: 0.777458  [  889/ 1000]\n",
      "loss: 0.650166, accuracy: 0.771133  [  890/ 1000]\n",
      "loss: 0.742821, accuracy: 0.760782  [  891/ 1000]\n",
      "loss: 0.680182, accuracy: 0.773433  [  892/ 1000]\n",
      "loss: 0.631325, accuracy: 0.772283  [  893/ 1000]\n",
      "loss: 0.615921, accuracy: 0.786659  [  894/ 1000]\n",
      "loss: 0.572124, accuracy: 0.788959  [  895/ 1000]\n",
      "loss: 0.579968, accuracy: 0.793559  [  896/ 1000]\n",
      "loss: 0.558790, accuracy: 0.791259  [  897/ 1000]\n",
      "loss: 0.566953, accuracy: 0.792984  [  898/ 1000]\n",
      "loss: 0.555917, accuracy: 0.790684  [  899/ 1000]\n",
      "loss: 0.562015, accuracy: 0.789534  [  900/ 1000]\n",
      "loss: 0.553625, accuracy: 0.790109  [  901/ 1000]\n",
      "loss: 0.560240, accuracy: 0.793559  [  902/ 1000]\n",
      "loss: 0.551704, accuracy: 0.790109  [  903/ 1000]\n",
      "loss: 0.561273, accuracy: 0.794710  [  904/ 1000]\n",
      "loss: 0.550603, accuracy: 0.788959  [  905/ 1000]\n",
      "loss: 0.567973, accuracy: 0.795860  [  906/ 1000]\n",
      "loss: 0.555762, accuracy: 0.790109  [  907/ 1000]\n",
      "loss: 0.595643, accuracy: 0.788384  [  908/ 1000]\n",
      "loss: 0.586478, accuracy: 0.775158  [  909/ 1000]\n",
      "loss: 0.652334, accuracy: 0.772283  [  910/ 1000]\n",
      "loss: 0.687775, accuracy: 0.765382  [  911/ 1000]\n",
      "loss: 0.659359, accuracy: 0.775158  [  912/ 1000]\n",
      "loss: 0.605287, accuracy: 0.780909  [  913/ 1000]\n",
      "loss: 0.606098, accuracy: 0.790109  [  914/ 1000]\n",
      "loss: 0.568200, accuracy: 0.788384  [  915/ 1000]\n",
      "loss: 0.579536, accuracy: 0.792984  [  916/ 1000]\n",
      "loss: 0.557213, accuracy: 0.790109  [  917/ 1000]\n",
      "loss: 0.567944, accuracy: 0.794710  [  918/ 1000]\n",
      "loss: 0.554372, accuracy: 0.790684  [  919/ 1000]\n",
      "loss: 0.563486, accuracy: 0.794710  [  920/ 1000]\n",
      "loss: 0.552366, accuracy: 0.790109  [  921/ 1000]\n",
      "loss: 0.562789, accuracy: 0.794710  [  922/ 1000]\n",
      "loss: 0.551037, accuracy: 0.789534  [  923/ 1000]\n",
      "loss: 0.566578, accuracy: 0.795285  [  924/ 1000]\n",
      "loss: 0.553032, accuracy: 0.790109  [  925/ 1000]\n",
      "loss: 0.582844, accuracy: 0.788959  [  926/ 1000]\n",
      "loss: 0.570950, accuracy: 0.779183  [  927/ 1000]\n",
      "loss: 0.632711, accuracy: 0.776883  [  928/ 1000]\n",
      "loss: 0.617942, accuracy: 0.767683  [  929/ 1000]\n",
      "loss: 0.664231, accuracy: 0.774583  [  930/ 1000]\n",
      "loss: 0.625035, accuracy: 0.772283  [  931/ 1000]\n",
      "loss: 0.628081, accuracy: 0.783209  [  932/ 1000]\n",
      "loss: 0.578571, accuracy: 0.787809  [  933/ 1000]\n",
      "loss: 0.582599, accuracy: 0.792984  [  934/ 1000]\n",
      "loss: 0.558184, accuracy: 0.790684  [  935/ 1000]\n",
      "loss: 0.567766, accuracy: 0.793559  [  936/ 1000]\n",
      "loss: 0.555143, accuracy: 0.791259  [  937/ 1000]\n",
      "loss: 0.562120, accuracy: 0.791259  [  938/ 1000]\n",
      "loss: 0.552949, accuracy: 0.790684  [  939/ 1000]\n",
      "loss: 0.560072, accuracy: 0.792984  [  940/ 1000]\n",
      "loss: 0.551110, accuracy: 0.790684  [  941/ 1000]\n",
      "loss: 0.560886, accuracy: 0.794710  [  942/ 1000]\n",
      "loss: 0.550000, accuracy: 0.788959  [  943/ 1000]\n",
      "loss: 0.567106, accuracy: 0.796435  [  944/ 1000]\n",
      "loss: 0.554347, accuracy: 0.790109  [  945/ 1000]\n",
      "loss: 0.592824, accuracy: 0.788384  [  946/ 1000]\n",
      "loss: 0.583082, accuracy: 0.775158  [  947/ 1000]\n",
      "loss: 0.658110, accuracy: 0.772283  [  948/ 1000]\n",
      "loss: 0.747263, accuracy: 0.760207  [  949/ 1000]\n",
      "loss: 0.673187, accuracy: 0.774583  [  950/ 1000]\n",
      "loss: 0.614307, accuracy: 0.779758  [  951/ 1000]\n",
      "loss: 0.607465, accuracy: 0.789534  [  952/ 1000]\n",
      "loss: 0.566515, accuracy: 0.788384  [  953/ 1000]\n",
      "loss: 0.575938, accuracy: 0.792984  [  954/ 1000]\n",
      "loss: 0.557334, accuracy: 0.791259  [  955/ 1000]\n",
      "loss: 0.564677, accuracy: 0.792409  [  956/ 1000]\n",
      "loss: 0.554713, accuracy: 0.790684  [  957/ 1000]\n",
      "loss: 0.560217, accuracy: 0.790109  [  958/ 1000]\n",
      "loss: 0.552527, accuracy: 0.790109  [  959/ 1000]\n",
      "loss: 0.558568, accuracy: 0.791259  [  960/ 1000]\n",
      "loss: 0.550646, accuracy: 0.790109  [  961/ 1000]\n",
      "loss: 0.559448, accuracy: 0.794710  [  962/ 1000]\n",
      "loss: 0.549377, accuracy: 0.789534  [  963/ 1000]\n",
      "loss: 0.565337, accuracy: 0.795860  [  964/ 1000]\n",
      "loss: 0.552967, accuracy: 0.790109  [  965/ 1000]\n",
      "loss: 0.589696, accuracy: 0.789534  [  966/ 1000]\n",
      "loss: 0.580594, accuracy: 0.776308  [  967/ 1000]\n",
      "loss: 0.656654, accuracy: 0.771133  [  968/ 1000]\n",
      "loss: 0.748691, accuracy: 0.760207  [  969/ 1000]\n",
      "loss: 0.680017, accuracy: 0.773433  [  970/ 1000]\n",
      "loss: 0.622687, accuracy: 0.775733  [  971/ 1000]\n",
      "loss: 0.609770, accuracy: 0.788959  [  972/ 1000]\n",
      "loss: 0.566871, accuracy: 0.788384  [  973/ 1000]\n",
      "loss: 0.575449, accuracy: 0.793559  [  974/ 1000]\n",
      "loss: 0.557498, accuracy: 0.790684  [  975/ 1000]\n",
      "loss: 0.564086, accuracy: 0.792409  [  976/ 1000]\n",
      "loss: 0.554803, accuracy: 0.790684  [  977/ 1000]\n",
      "loss: 0.559535, accuracy: 0.790684  [  978/ 1000]\n",
      "loss: 0.552530, accuracy: 0.790109  [  979/ 1000]\n",
      "loss: 0.557665, accuracy: 0.790109  [  980/ 1000]\n",
      "loss: 0.550562, accuracy: 0.790109  [  981/ 1000]\n",
      "loss: 0.558037, accuracy: 0.794710  [  982/ 1000]\n",
      "loss: 0.549022, accuracy: 0.790109  [  983/ 1000]\n",
      "loss: 0.562377, accuracy: 0.795285  [  984/ 1000]\n",
      "loss: 0.550420, accuracy: 0.789534  [  985/ 1000]\n",
      "loss: 0.580321, accuracy: 0.791259  [  986/ 1000]\n",
      "loss: 0.570412, accuracy: 0.777458  [  987/ 1000]\n",
      "loss: 0.640537, accuracy: 0.771708  [  988/ 1000]\n",
      "loss: 0.684579, accuracy: 0.763657  [  989/ 1000]\n",
      "loss: 0.680384, accuracy: 0.773433  [  990/ 1000]\n",
      "loss: 0.686426, accuracy: 0.769408  [  991/ 1000]\n",
      "loss: 0.621632, accuracy: 0.784359  [  992/ 1000]\n",
      "loss: 0.572939, accuracy: 0.788384  [  993/ 1000]\n",
      "loss: 0.577458, accuracy: 0.792984  [  994/ 1000]\n",
      "loss: 0.557443, accuracy: 0.791834  [  995/ 1000]\n",
      "loss: 0.564479, accuracy: 0.792409  [  996/ 1000]\n",
      "loss: 0.554607, accuracy: 0.790684  [  997/ 1000]\n",
      "loss: 0.559510, accuracy: 0.790684  [  998/ 1000]\n",
      "loss: 0.552270, accuracy: 0.790109  [  999/ 1000]\n",
      "loss: 0.557462, accuracy: 0.790109  [ 1000/ 1000]\n"
     ]
    }
   ],
   "source": [
    "trainer(\n",
    "    train_dataloader=space_train_dataloader,\n",
    "    val_dataloader=space_val_dataloader,\n",
    "    custom_model=custom_model,\n",
    "    loss_model=loss_model,\n",
    "    optimiser=optimiser,\n",
    "    iterations=1000,\n",
    "    print_stats=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15668/3099664285.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(predictions, dtype=bool)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for (X,_) in space_test_dataloader:\n",
    "        predictions = custom_model(X).round()\n",
    "torch.tensor(predictions, dtype=bool)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('spaceship')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9aafca8e7821aa7c4959e6bd2d8c2bf1dc692184d1d7338f519742589bf0d665"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
